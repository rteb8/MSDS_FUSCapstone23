{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H28_8PsI5HQw","executionInfo":{"status":"ok","timestamp":1714061188369,"user_tz":240,"elapsed":20068,"user":{"displayName":"Reanna Panagides","userId":"06524198769902062008"}},"outputId":"2fc909eb-9be4-46f0-def7-b69577e232a1"},"id":"H28_8PsI5HQw","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"id":"3daaa326-50b3-4231-8eb3-840943ccf4de","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"3daaa326-50b3-4231-8eb3-840943ccf4de","executionInfo":{"status":"ok","timestamp":1714061204368,"user_tz":240,"elapsed":12018,"user":{"displayName":"Reanna Panagides","userId":"06524198769902062008"}},"outputId":"f0a7fe33-4eb5-403f-8e9a-c2aed26c6222"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":5}],"source":["import torch\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","# path where the model and tokenizer were saved\n","model_save_path = '/content/drive/MyDrive/MSDS Capstone/FUS_handover/fusBERT.pt'\n","tokenizer_save_path = '/content/drive/MyDrive/MSDS Capstone/FUS_handover/tokenizer'\n","\n","# initialize the model and tokenizer\n","model = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=2)\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_save_path)\n","\n","# load the model's state_dict\n","model.load_state_dict(torch.load(model_save_path))\n","\n","model.eval()"]},{"cell_type":"code","execution_count":6,"id":"213fe47d-c899-403f-aa39-3b703c1bc590","metadata":{"tags":[],"id":"213fe47d-c899-403f-aa39-3b703c1bc590","executionInfo":{"status":"ok","timestamp":1714061216626,"user_tz":240,"elapsed":167,"user":{"displayName":"Reanna Panagides","userId":"06524198769902062008"}}},"outputs":[],"source":["def predict_abstract(abstract):\n","    # Ensure the model is on the correct device (GPU or CPU)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    # Tokenize the input abstract\n","    inputs = tokenizer(abstract, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n","\n","    # Move the tokenized inputs to the same device as the model\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","    # Predict\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","\n","    # Print the raw logits\n","    # print(\"Raw logits:\", logits)\n","\n","    # Convert logits to probabilities using softmax\n","    probs = torch.nn.functional.softmax(logits, dim=1)\n","    confidence, prediction = torch.max(probs, dim=1)\n","\n","    # Move predictions back to CPU for easy handling (if they were on GPU)\n","    confidence = confidence.cpu().item() * 100  # as percentage\n","    prediction = prediction.cpu().item()  # binary indication\n","\n","    return prediction, confidence, logits.cpu().numpy()\n"]},{"cell_type":"code","execution_count":null,"id":"4d50fbcc-2c31-4596-9d4c-bfb3962a791d","metadata":{"tags":[],"id":"4d50fbcc-2c31-4596-9d4c-bfb3962a791d"},"outputs":[],"source":["#!pip install openpyxl"]},{"cell_type":"code","execution_count":8,"id":"a3b092d9-0732-4476-a26a-6180318f57f5","metadata":{"tags":[],"id":"a3b092d9-0732-4476-a26a-6180318f57f5","executionInfo":{"status":"ok","timestamp":1714061277245,"user_tz":240,"elapsed":745,"user":{"displayName":"Reanna Panagides","userId":"06524198769902062008"}}},"outputs":[],"source":["# read in excel sheet\n","import pandas as pd\n","import openpyxl\n","\n","file_path = '/content/drive/MyDrive/MSDS Capstone/FUS_handover/Sample Data.xlsx' #update file path to relevant file\n","df = pd.read_excel(file_path)"]},{"cell_type":"code","execution_count":10,"id":"d1abfbaf-2d33-4779-a5df-c06f1a907ce6","metadata":{"tags":[],"id":"d1abfbaf-2d33-4779-a5df-c06f1a907ce6","executionInfo":{"status":"ok","timestamp":1714061306458,"user_tz":240,"elapsed":546,"user":{"displayName":"Reanna Panagides","userId":"06524198769902062008"}}},"outputs":[],"source":["# Prediction and confidence assignment\n","predictions, confidences, raw_logits = [], [], []\n","\n","df['Abstract'] = df['Abstract'].dropna()\n","df['Abstract'] =df['Abstract'].astype(str)\n","df['Abstract'] = [x.lower() for x in df['Abstract']]\n","df = df.drop_duplicates(subset='Abstract', keep='first')\n","\n","for abstract in df['Abstract']:\n","    prediction, confidence, logits = predict_abstract(abstract)\n","    predictions.append(prediction)\n","    confidences.append(confidence)\n","    raw_logits.append(logits.tolist())  # Convert numpy array to list for DataFrame compatibility\n","\n","# Add the new data to the DataFrame\n","df['Prediction'] = predictions\n","df['Confidence'] = confidences\n","df['Logits'] = raw_logits\n","\n","\n","# Update DataFrame\n","df['Prediction'] = predictions\n","df['Confidence'] = confidences\n","\n","# Save to a new Excel file\n","output_file_path = '/content/drive/MyDrive/MSDS Capstone/FUS_handover/double_updated_test.xlsx'\n","df.to_excel(output_file_path, index=False)"]}],"metadata":{"kernelspec":{"display_name":"PyTorch 2.0.1","language":"python","name":"pytorch-2.0.1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}