{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5c7608-0ba1-4a12-bfa0-b4286b2a6d5e",
   "metadata": {},
   "source": [
    "# Comparing FusBERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c10ad0a5-f911-41dc-af8b-33dacdcd49b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, set_seed, AutoTokenizer, AutoModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692ed444-1075-4c91-aeb7-6cf1e2c917af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc7b2c1-db7f-46da-a48e-da72e06f54be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72bc25-440b-4902-aec3-043ea62a03f3",
   "metadata": {},
   "source": [
    "## Setting the Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ebd420-dc76-4d49-a74b-0765877e7ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(6013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946a49f-f637-4438-b7fb-9dda8d67202e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be267ea-b922-4859-9e62-78e2a62431cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: self.encodings[key][idx] for key in self.encodings}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Note the dtype change for binary classification\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa172d7-f8ee-4aae-acc4-3cf3f6264ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    learning_rate=0.001, \n",
    "    report_to=None,\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    logging_strategy=\"epoch\"  # Log at the end of each epoch\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=1)  # Adjust zero_division here\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc979a2-582f-4d62-b417-a1c6c8087b80",
   "metadata": {},
   "source": [
    "## Creating fusBERT with pretrained bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e9dd185-5550-4680-919f-778fdaa67763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('zotero_data.csv')\n",
    "dat['abstract'] = dat['abstract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12d72d23-c8fe-48b8-9fd4-3511677e4a90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: [1794 1794]\n"
     ]
    }
   ],
   "source": [
    "labels = dat['fus_related'].tolist()\n",
    "print(\"Label distribution:\", np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef921ef9-1278-4aec-adb1-7e3bc386c6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "tokenized_data = tokenizer(list(dat['abstract']), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9eb6a8d-5601-4408-87ac-c4dd96e3a34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = AbstractsDataset(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "359e0923-83b4-4661-8de8-227081b84e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split indices into train and test sets first\n",
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "\n",
    "# Split train indices into train and validation sets\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ca722fc-1864-4c1d-9562-fb8fbac79e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:835: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48efe690-88f7-494b-8741-1572a99699bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkp3em/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.create_optimizer_and_scheduler(num_training_steps=1000)\n",
    "trainer.optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "trainer.lr_scheduler = get_linear_schedule_with_warmup(trainer.optimizer, num_warmup_steps=500, num_training_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e31a6ee-a757-46c4-b7a2-cbd6749a1775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='364' max='364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [364/364 00:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.179084</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.951009</td>\n",
       "      <td>0.921788</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=364, training_loss=0.3934280060149811, metrics={'train_runtime': 50.6908, 'train_samples_per_second': 57.328, 'train_steps_per_second': 7.181, 'total_flos': 764600726876160.0, 'train_loss': 0.3934280060149811, 'epoch': 1.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0edb38fc-f937-4b91-b8a3-dfbb3a3cf8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17908445000648499,\n",
       " 'eval_accuracy': 0.9473684210526315,\n",
       " 'eval_f1': 0.9510086455331412,\n",
       " 'eval_precision': 0.9217877094972067,\n",
       " 'eval_recall': 0.9821428571428571,\n",
       " 'eval_runtime': 1.3973,\n",
       " 'eval_samples_per_second': 231.16,\n",
       " 'eval_steps_per_second': 15.029,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b48bab8-7b09-41ff-8775-e455c055bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31911733746528625,\n",
       " 'eval_accuracy': 0.9080779944289693,\n",
       " 'eval_f1': 0.9119999999999999,\n",
       " 'eval_precision': 0.8423645320197044,\n",
       " 'eval_recall': 0.9941860465116279,\n",
       " 'eval_runtime': 1.5904,\n",
       " 'eval_samples_per_second': 225.727,\n",
       " 'eval_steps_per_second': 14.462,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98236d-2b21-4655-902a-efa1bff8ec68",
   "metadata": {},
   "source": [
    "## Creating fusBERT with pretrained tinyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "660c4faa-5ecb-4762-bd43-279a34f3cbc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zotero = pd.read_csv('zotero_data.csv')\n",
    "zotero['abstract'] = zotero['abstract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18004a06-c8ec-4452-b6eb-b59352ad0d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "tokenized_data = tokenizer(list(zotero['abstract']), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acd4ddab-1e51-44f1-aa8e-b153d0d4f306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: [1794 1794]\n"
     ]
    }
   ],
   "source": [
    "labels = zotero['fus_related'].tolist()\n",
    "print(\"Label distribution:\", np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8573482-4c99-450f-9740-7ecc7d3a69b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = AbstractsDataset(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72ea7fe6-e273-4dfd-856c-bb2ee236da26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split indices into train and test sets first\n",
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "\n",
    "# Split train indices into train and validation sets\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ff39053-a7c2-4f29-83ed-350efd6e7def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c957d19-fe14-4caf-bda5-ef68cc19a1bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkp3em/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.create_optimizer_and_scheduler(num_training_steps=1000)\n",
    "trainer.optimizer = torch.optim.AdamW(model.parameters(), lr= 5e-5)\n",
    "trainer.lr_scheduler = get_linear_schedule_with_warmup(trainer.optimizer, num_warmup_steps=500, num_training_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf1ef6e8-076f-4b67-a4dd-3a7e9df202c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='364' max='364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [364/364 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.382863</td>\n",
       "      <td>0.873065</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.904459</td>\n",
       "      <td>0.845238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=364, training_loss=0.5477914076585036, metrics={'train_runtime': 10.6541, 'train_samples_per_second': 272.76, 'train_steps_per_second': 34.165, 'total_flos': 41669123026944.0, 'train_loss': 0.5477914076585036, 'epoch': 1.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b7a9938-6be4-48e2-bb77-0c0f0a14cb6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3828626871109009,\n",
       " 'eval_accuracy': 0.8730650154798761,\n",
       " 'eval_f1': 0.8738461538461538,\n",
       " 'eval_precision': 0.9044585987261147,\n",
       " 'eval_recall': 0.8452380952380952,\n",
       " 'eval_runtime': 0.3079,\n",
       " 'eval_samples_per_second': 1049.103,\n",
       " 'eval_steps_per_second': 68.208,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc3974e3-a5af-4b6a-9421-4140b06c69a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4655163288116455,\n",
       " 'eval_accuracy': 0.8328690807799443,\n",
       " 'eval_f1': 0.8333333333333334,\n",
       " 'eval_precision': 0.7978723404255319,\n",
       " 'eval_recall': 0.872093023255814,\n",
       " 'eval_runtime': 0.3698,\n",
       " 'eval_samples_per_second': 970.805,\n",
       " 'eval_steps_per_second': 62.196,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c38faa-83f6-47b4-9d9a-d513aab5f9ab",
   "metadata": {},
   "source": [
    "## Creating fusBERT with pretrained distilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9af017d-ca71-44cb-8f50-befeca8f9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('zotero_data.csv')\n",
    "dat['abstract'] = dat['abstract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77de2a19-9778-457b-b2b0-6f44781e1431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenized_data = tokenizer(list(dat['abstract']), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9ce3c67-d904-4a3c-9966-b27635dd3f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: [1794 1794]\n"
     ]
    }
   ],
   "source": [
    "labels = dat['fus_related'].tolist()\n",
    "print(\"Label distribution:\", np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "173ab4dd-e63e-41ba-803a-9a60285bc4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = AbstractsDataset(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "330cdfd5-dceb-4713-8ac6-fa8c988c2b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split indices into train and test sets first\n",
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "\n",
    "# Split train indices into train and validation sets\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1393ea-d75d-44b3-89c8-f08455ed0a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cecc5c9-fa4a-476f-8eaa-3b1f184f5c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkp3em/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.create_optimizer_and_scheduler(num_training_steps=1000)\n",
    "trainer.optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "trainer.lr_scheduler = get_linear_schedule_with_warmup(trainer.optimizer, num_warmup_steps=500, num_training_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40870855-0a4c-43bf-8fce-e141389d0814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='364' max='364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [364/364 00:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.159820</td>\n",
       "      <td>0.953560</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=364, training_loss=0.3696788326724545, metrics={'train_runtime': 26.9732, 'train_samples_per_second': 107.736, 'train_steps_per_second': 13.495, 'total_flos': 384950260494336.0, 'train_loss': 0.3696788326724545, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f10e298-4c61-4a1c-ac4a-31d36d6d0c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1598198562860489,\n",
       " 'eval_accuracy': 0.9535603715170279,\n",
       " 'eval_f1': 0.9570200573065902,\n",
       " 'eval_precision': 0.9226519337016574,\n",
       " 'eval_recall': 0.9940476190476191,\n",
       " 'eval_runtime': 0.7358,\n",
       " 'eval_samples_per_second': 438.993,\n",
       " 'eval_steps_per_second': 28.541,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14bdaee1-11a0-4f90-b268-1c18b69a8380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29590103030204773,\n",
       " 'eval_accuracy': 0.8997214484679665,\n",
       " 'eval_f1': 0.9047619047619048,\n",
       " 'eval_precision': 0.8300970873786407,\n",
       " 'eval_recall': 0.9941860465116279,\n",
       " 'eval_runtime': 0.8358,\n",
       " 'eval_samples_per_second': 429.539,\n",
       " 'eval_steps_per_second': 27.519,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212173f0-5bdb-42ef-aa4a-15eb451a8a1d",
   "metadata": {},
   "source": [
    "## Creating fusBERT with pretrained sciBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf97b5d-d351-4f63-89d5-6b786e5f27cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('zotero_data.csv')\n",
    "dat['abstract'] = dat['abstract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc8588a9-a43c-4e91-9dd2-35957b61009a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: [1794 1794]\n"
     ]
    }
   ],
   "source": [
    "labels = dat['fus_related'].tolist()\n",
    "print(\"Label distribution:\", np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ffb2e8a-6685-4d0e-bcfb-1adf894d9c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "tokenized_data = tokenizer(list(dat['abstract']), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfadac4-d997-4723-bfb2-27ca6009a206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = AbstractsDataset(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7de26d4-8f88-4f8d-a032-1e96ad25ba59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split indices into train and test sets first\n",
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "\n",
    "# Split train indices into train and validation sets\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cfc8208-05a0-4783-9fdb-52d93ca7002a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788975be81154b22a7fdc7886a27934d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:835: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbed3213-8cff-4114-a9a2-20485ce7fded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkp3em/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.create_optimizer_and_scheduler(num_training_steps=1000)\n",
    "trainer.optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "trainer.lr_scheduler = get_linear_schedule_with_warmup(trainer.optimizer, num_warmup_steps=500, num_training_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b671ba2-b8b3-4c5c-ae2e-346e7f0799cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='364' max='364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [364/364 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.158074</td>\n",
       "      <td>0.956656</td>\n",
       "      <td>0.959770</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=364, training_loss=0.3630312825297261, metrics={'train_runtime': 52.5498, 'train_samples_per_second': 55.3, 'train_steps_per_second': 6.927, 'total_flos': 764600726876160.0, 'train_loss': 0.3630312825297261, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1569c91c-fb9f-44e0-b97c-6049786c57fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.15807422995567322,\n",
       " 'eval_accuracy': 0.9566563467492261,\n",
       " 'eval_f1': 0.9597701149425287,\n",
       " 'eval_precision': 0.9277777777777778,\n",
       " 'eval_recall': 0.9940476190476191,\n",
       " 'eval_runtime': 1.4531,\n",
       " 'eval_samples_per_second': 222.287,\n",
       " 'eval_steps_per_second': 14.452,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "572757d8-2ef9-41a9-9c1b-e0c1a4449690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3061637282371521,\n",
       " 'eval_accuracy': 0.9164345403899722,\n",
       " 'eval_f1': 0.9193548387096774,\n",
       " 'eval_precision': 0.855,\n",
       " 'eval_recall': 0.9941860465116279,\n",
       " 'eval_runtime': 1.5956,\n",
       " 'eval_samples_per_second': 224.997,\n",
       " 'eval_steps_per_second': 14.415,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23143c5-7899-4abd-a3af-86e33c43c659",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d4f187b-ca28-4711-87b0-a990c2ba25d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('zotero_data.csv')\n",
    "df['abstract'] = df['abstract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "467e4fe2-0a43-40c8-b401-af5e06d46f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['abstract']\n",
    "y = df['fus_related']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.1,random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "\n",
    "#kinda like scaling here\n",
    "tfidf.fit(X_train)\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d0c6578-fed5-4c05-8701-b789b986d84a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words used for Non-FUS Articles.\n",
      "[('patients', 2718), ('care', 2349), ('delirium', 2301), ('hpv', 1595), ('study', 1427), ('icu', 1336), ('health', 1255), ('results', 1231), ('ultrasound', 1162), ('nurses', 1106), ('methods', 939), ('19', 931), ('data', 845), ('patient', 835), ('intensive', 831), ('vaccination', 822), ('vaccine', 811), ('using', 805), ('used', 787), ('covid', 786), ('clinical', 776), ('risk', 775), ('use', 742), ('based', 734), ('social', 700), ('studies', 689), ('treatment', 678), ('associated', 639), ('95', 625), ('high', 612), ('knowledge', 571), ('critical', 562), ('assessment', 558), ('women', 557), ('intervention', 545), ('cancer', 544), ('ci', 540), ('unit', 540), ('screening', 516), ('group', 510)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "matrix = cv.fit_transform(df[df['fus_related']==0]['abstract'])\n",
    "freqs = zip(cv.get_feature_names_out(), matrix.sum(axis=0).tolist()[0])\n",
    "# sort from largest to smallest\n",
    "print(\"Top 20 words used for Non-FUS Articles.\")\n",
    "print(sorted(freqs, key=lambda x: -x[1])[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a93860f6-6b73-4c63-b1a6-f601cfd661cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words used for FUS Articles\n",
      "[('ultrasound', 3458), ('treatment', 2866), ('focused', 2169), ('hifu', 2101), ('patients', 2020), ('fus', 1655), ('brain', 1653), ('results', 1432), ('high', 1327), ('study', 1198), ('using', 1169), ('ablation', 1120), ('clinical', 1074), ('intensity', 1066), ('imaging', 1043), ('tumor', 980), ('methods', 958), ('used', 924), ('therapy', 901), ('tissue', 782), ('effects', 772), ('group', 770), ('cancer', 758), ('non', 734), ('based', 715), ('bbb', 712), ('time', 712), ('delivery', 694), ('studies', 678), ('guided', 668), ('acoustic', 666), ('mrgfus', 660), ('model', 644), ('tremor', 616), ('mri', 612), ('therapeutic', 612), ('compared', 598), ('blood', 594), ('low', 588), ('method', 583)]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "matrix = cv.fit_transform(df[df['fus_related']==1]['abstract'])\n",
    "freqs = zip(cv.get_feature_names_out(), matrix.sum(axis=0).tolist()[0])\n",
    "# sort from largest to smallest\n",
    "print(\"Top 20 words used for FUS Articles\")\n",
    "print(sorted(freqs, key=lambda x: -x[1])[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee225fd6-5d72-4eb6-ac99-1c776f191af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "def test_model(model):\n",
    "\n",
    "    y_preds = model.predict(X_test_tfidf)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_preds)\n",
    "    precision = precision_score(y_test, y_preds, average='weighted')\n",
    "    recall = recall_score(y_test, y_preds, average='weighted')\n",
    "    f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3244f9-e5ec-4dbe-8cb4-c75c69b3c6f5",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e47b7d8e-899d-4696-a4d9-fc6c9a635625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAIVE BAYES\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0be864f-9e25-4c9d-ab2b-ac4abcff4819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8746518105849582\n",
      "Precision: 0.8921217452341922\n",
      "Recall: 0.8746518105849582\n",
      "F1 Score: 0.87385713916597\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES\n",
    "test_model(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f4264-e78e-4786-af21-b6b422b62c14",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "977c7dab-4cf4-4b52-a18b-cb081765384a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(max_iter=10000000)\n",
    "\n",
    "log_model.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fff66e3a-6e35-41a9-bef2-7948c1517dce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8997214484679665\n",
      "Precision: 0.9102384331038349\n",
      "Recall: 0.8997214484679665\n",
      "F1 Score: 0.89943785880455\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "test_model(log_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6c587-eea1-4f1e-9f99-2606dc2807b5",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23b0a4ba-dffd-4408-972a-2efb575dfd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SUPPORT VECTOR MACHINE\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "\n",
    "rbf_svc = SVC(probability=True)\n",
    "rbf_svc.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f7b0df9-d27c-4751-923d-9f82733e9f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8885793871866295\n",
      "Precision: 0.8975011101691494\n",
      "Recall: 0.8885793871866295\n",
      "F1 Score: 0.888331901202903\n"
     ]
    }
   ],
   "source": [
    "#SUPPORT VECTOR MACHINE\n",
    "test_model(rbf_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec5aa4-68e7-4ee8-8451-7bc2d1d53108",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "899657f9-1960-4a6b-8ff7-ea91fcc6faa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = LinearSVC(dual=True)\n",
    "linear_svc.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "740f1e1e-0a37-49e0-a215-72acf9402c11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8774373259052924\n",
      "Precision: 0.8817610772162892\n",
      "Recall: 0.8774373259052924\n",
      "F1 Score: 0.8773859696417046\n"
     ]
    }
   ],
   "source": [
    "#LINEAR SUPPORT VECTOR MACHINE\n",
    "test_model(linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3279d-c321-42c4-ad83-f9053a86703e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
